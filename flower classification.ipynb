{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **Flower Classification CNN**"},{"metadata":{},"cell_type":"markdown","source":"This was a hackerearth challenge\n\nGiven a large class of flowers, 102 to be precise. Build a flower classification model which is discriminative between classes but can correctly classify all flower images belonging to the same class. There are a total of 20549 (train + test) images of flowers. Predict the category of the flowers present in the test folder with good accuracy.\n"},{"metadata":{},"cell_type":"markdown","source":"Data modelling: https://github.com/tsaideepak7/flower-classification "},{"metadata":{},"cell_type":"markdown","source":"# **Model Building and Training**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers.core import Flatten, Dense, Dropout\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom keras.models import load_model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image\nfrom keras import models\n\nimport pandas as pd\nimport numpy as np\nimport time\nimport datetime\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images = 40591 #number of train images\nval_images = 10101 #number of validation images\ntrain_batchsize = 50 #number of train images in each batch\nval_batchsize = 50 #number of validation images in each batch\nimg_shape=(128,128) #image shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#since the dataset is huge, we use generators to train the model\ntrain_datagen = ImageDataGenerator(rescale=1./255)\nx_train = train_datagen.flow_from_directory(\n    directory=r'../input/flower-datatree/datatree/train/', #location of train images\n    batch_size=train_batchsize,\n    target_size=img_shape,\n    class_mode=\"categorical\", #classification \n    shuffle=True, #shuffling the train images\n    seed=42 #seed for the shuffle\n)\n\nvalidation_datagen = ImageDataGenerator(rescale=1./255)\nx_validation = validation_datagen.flow_from_directory(\n    directory=r'../input/flower-datatree/datatree/validation/', #location of validation images\n    batch_size=val_batchsize,\n    target_size=img_shape,\n    class_mode=\"categorical\", #classification\n    shuffle=True, #shuffling the validation images\n    seed=42 #seed for the shuffle\n)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#building the model architecture\nmodel = Sequential()\nmodel.add(Conv2D(16,(5,5),activation='relu',input_shape=(128,128,3)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.1))\n\nmodel.add(Conv2D(20,(3,3),activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(3,3)))\nmodel.add(Dropout(0.1))\n\nmodel.add(Conv2D(20,(3, 3),activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.1))\n\nmodel.add(Flatten())\nmodel.add(Dropout(0.1))\nmodel.add(Dense(102,activation='softmax'))\n\nmodel.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_steps=int(np.ceil(train_images//train_batchsize)) #number of steps for training the model\nval_steps=int(np.ceil(val_images//val_batchsize)) #number of steps for validating the model\nprint(train_steps,val_steps)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=3, verbose=1, mode='auto')\n# Reducing the learning Rate if result is not improving\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', min_delta=0.0004, patience=2, factor=0.1, min_lr=1e-6, mode='auto',verbose=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"savepath=\"flowermodel.hdf5\"\ncheckpoint = ModelCheckpoint(savepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max') \n#saves the model only with the highest validation accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start=time.time()\ncnn=model.fit_generator(x_train,steps_per_epoch = train_steps,validation_data=x_validation,validation_steps = val_steps,epochs=80,callbacks=[early_stop, reduce_lr , checkpoint],verbose=1)  \nend=time.time()\n\nprint('training time: '+str(datetime.timedelta(seconds=(end-start))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#accuracy\nprint(cnn.history.keys())\nplt.plot(cnn.history['acc'])\nplt.plot(cnn.history['val_acc'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.plot(np.argmax(cnn.history[\"val_acc\"]), np.max(cnn.history[\"val_acc\"]), marker=\"x\", color=\"r\",label=\"best model\")\nplt.legend(['Training set', 'Test set','best'], loc='upper left')\nplt.show()\n\n#loss\nplt.plot(cnn.history['loss'])\nplt.plot(cnn.history['val_loss'])\nplt.title('Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Training set', 'Test set'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Visualizing intermediate activation layers of the model**\n> > "},{"metadata":{"trusted":true},"cell_type":"code","source":"no_layers=9 #number of layers to inspect","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"layer_outputs = [layer.output for layer in model.layers[:no_layers]] #extract output of the layers\nactivation_model = models.Model(inputs=model.input, outputs=layer_outputs) # creates a model that will return these outputs, given the model input","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_path = r'../input/flower-datatree/datatree/test/19791.jpg' #select a image\nimg = image.load_img(img_path, target_size=img_shape)\nimg_tensor = image.img_to_array(img)\nimg_tensor = np.expand_dims(img_tensor, axis=0)\nimg_tensor /= 255.\nplt.imshow(img_tensor[0])\nplt.show()\nprint(img_tensor.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"activations = activation_model.predict(img_tensor) # returns a list of Numpy arrays: one array per layer activation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"first_layer_activation = activations[0]\nprint(first_layer_activation.shape)\nplt.matshow(first_layer_activation[0, :, :, 1], cmap='viridis') #choosing any one output from one of the filter in the first layer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nlayer_names = []\nfor layer in model.layers[:no_layers]:\n    layer_names.append(layer.name) # names of the layers, so you can have them as part of your plot\n    \nimages_per_row = 16  #number of images per row while displaying the filter outputs\n\nfor layer_name, layer_activation in zip(layer_names, activations): # displays the feature maps\n    n_features = layer_activation.shape[-1] # number of features in the feature map\n    size = layer_activation.shape[1] #the feature map has shape (1, size, size, n_features).\n    n_cols = n_features // images_per_row # tiles the activation channels in this matrix\n    display_grid = np.zeros((size * n_cols, images_per_row * size))\n    for col in range(n_cols): # tiles each filter into a horizontal grid\n        for row in range(images_per_row):\n            channel_image = layer_activation[0,:,:,col * images_per_row + row]\n            channel_image -= channel_image.mean() # post-processes the feature to make it visually palatable\n            channel_image /= channel_image.std()\n            channel_image *= 64\n            channel_image += 128\n            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n            display_grid[col * size : (col + 1) * size,row * size : (row + 1) * size] = channel_image # displays the grid\n    scale = 1. / size\n    plt.figure(figsize=(scale * display_grid.shape[1],scale * display_grid.shape[0]))\n    plt.title(layer_name)\n    plt.grid(False)\n    plt.imshow(display_grid, aspect='auto', cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Predciting test data using the trained model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_datagen = ImageDataGenerator(rescale=1./255)\nx_test = test_datagen.flow_from_directory(\n    directory=r'../input/flower-datatree/datatree/',\n    target_size=img_shape,\n    classes=['test'],\n    batch_size=1,\n    shuffle=False\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_images = 2009\n\ntest_stepsize = test_images\nx_test.reset() #\npredict = model.predict_generator(x_test ,steps=test_stepsize , verbose=1)\nprint(predict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions=[] #saving all the prediction on the test images\nfor i in predict:\n    predictions.append(np.argmax(i)+1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#undoing the sorting of the categories caused by ImageDataGenerator\n####very very important####\nactual=[str(i) for i in range(1,103)]\ngen=sorted(actual)\n\nlabels={}\n\nfor i in range(1,103):\n    labels[i]=int(gen[i-1])\nn_predictions=[]\nfor i in predictions:\n    n_predictions.append(labels[i])\n\npredictions = n_predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\nfreq=Counter()\nfreq.update(predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pylab as plt\n\nlists = sorted(freq.items()) # sorted by key, return a list of tuples\nx, y = zip(*lists) # unpack a list of pairs into two tuples\nplt.figure(figsize=(20,5))\nplt.bar(x, y)\nplt.xlabel('category')\nplt.ylabel('number of images')\nplt.title(\"test results\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"names=[i for i in range(18540,20549)]\nresults = pd.Series(predictions,name = \"category\")\nnames=pd.Series(names,name = \"image_id\")\nsubmission = pd.concat([names,results],axis = 1)\nsubmission.to_csv(\"output.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}